# Дилемма заключенного с обучением агентов на Python

Этот проект моделирует **дилемму заключенного** с использованием методов обучения с подкреплением. Классическая дилемма заключенного иллюстрирует конфликт между личными интересами и общественным благом, где два агента могут выбрать сотрудничество или предательство.

В данном коде агенты обучаются на основе получаемых наград, постепенно адаптируя свои стратегии. С помощью **Q-обучения** агенты изменяют свои предпочтения в зависимости от предыдущих взаимодействий, стремясь максимизировать свои награды.

### Основные особенности реализации:

- **Класс PrisonersDilemma**: задаёт правила игры, определяя награды для каждой комбинации действий агентов.
- **Класс Agent**: описывает агента, использующего алгоритм Q-обучения для выбора стратегии. Агенты могут выбирать между:
  - **Сотрудничеством** (сокращает тюремный срок обоим агентам).
  - **Предательством** (агент получает максимальную выгоду, если другой агент сотрудничает).
- **Q-обучение**: агенты оптимизируют свои действия, учитывая прошлые взаимодействия. Этот процесс позволяет агентам находить стратегии, обеспечивающие максимальное вознаграждение.

### Параметры Q-обучения

Код использует несколько гиперпараметров, задающих поведение агентов:
- **learning_rate**: скорость обучения, которая определяет, насколько обновляется знание агента после каждого раунда.
- **discount_factor**: коэффициент дисконтирования, который определяет, насколько агент учитывает будущие награды при принятии текущих решений.
- **exploration_rate**: вероятность случайного выбора действия (эпсилон-жадная стратегия), чтобы исследовать альтернативные действия.

### Визуализация результатов

График показывает **накопленные награды** каждого агента в ходе игры. Это наглядно демонстрирует, как обучение влияет на результаты агентов, позволяя увидеть, оптимизируют ли агенты свои стратегии для достижения максимального вознаграждения.

### Структура кода

```python
class PrisonersDilemma:
    # Определение наград для различных действий (сотрудничество или предательство)

class Agent:
    # Реализация агента с Q-обучением для выбора оптимальной стратегии

def simulate_game(agent1, agent2, rounds=100):
    # Моделирование игры с участием двух агентов, обучение и сбор результатов
```

### Пример использования

В блоке simulate_game создаются два агента и моделируется игра, где агенты на протяжении 1000 раундов выбирают свои действия на основе стратегии Q-обучения. Накопленные награды визуализируются, позволяя оценить, насколько эффективно агенты адаптируются к повторяющимся взаимодействиям.
