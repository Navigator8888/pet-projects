# Моделирование конфликтов с помощью теории игр

## Описание:
Данный проект посвящён моделированию военных конфликтов с использованием теории игр. Используется упрощённая версия Q-обучения для определения оптимальных стратегий нескольких игроков (или сторон конфликта), которые могут изменять свои действия в зависимости от внешних факторов и успехов в предыдущих раундах. В проекте учитываются такие факторы, как динамическое взаимодействие, разрушение альянсов, учёт различных типов игроков (агрессивные, осторожные и сбалансированные), а также влияние внешней среды на матрицы выплат.

## Основные возможности:
- Поддержка нескольких игроков и стратегий.
- Динамическое пересмотрение альянсов, включая их разрушение при ухудшении общих выигрышей.
- Обучение на основе метода Q-обучения для адаптации стратегий с течением времени.
- Добавление различных типов игроков: агрессивные, осторожные и сбалансированные, что влияет на выбор стратегии.
- Включение внешних факторов, таких как сезонные изменения и случайные события, влияющих на матрицы выплат.

## Применение:
Проект может быть полезен для анализа взаимодействий в конфликтах, оценки стратегических рисков и прогнозирования поведения участников, например, в контексте международных отношений или локальных конфликтов.

## Технологии:
Python (использование библиотек NumPy и random)
Реализация упрощённого Q-обучения без использования сложных нейронных сетей.

--------

Для анализа военных стратегий с помощью теории игр можно использовать подходы, подобные классической дилемме заключённого или моделированию игр с нулевой суммой. 
В этом коде смоделирован конфликт между несколькими игроками, каждый из которых может выбирать из нескольких стратегий. Мы будем использовать матрицу выплат, чтобы определить результат каждого возможного сочетания стратегий.

### Основная идея:
- Несколько противников выбирают свои действия независимо.
- У каждого игрока есть несколько стратегий: Атаковать, Защищаться, Отступить, Маневрировать или Переговоры.
- Выплаты (результаты) зависят от выбранной стратегии всех игроков.
- Будем использовать матрицы выплат и симулировать раунды для предсказания действий игроков.
- 
### Ключевые функции модели:

#### Динамическая матрица выплат: 
Выплаты каждого игрока зависят от сочетания выбранных стратегий. Мы добавили случайные эффекты и сезонные изменения, чтобы сделать матрицу выплат более реалистичной и динамичной.

#### Альянсы: 
Игроки могут образовывать альянсы, чтобы действовать совместно. Альянсы пересматриваются после каждого раунда, и они могут быть разрушены, если общие выигрыши участников становятся ниже определенного порога.

#### Q-обучение: 
R-Игроки учатся выбирать стратегии с течением времени, используя Q-обучение. Это помогает им улучшать свои действия на основе прошлого опыта.

#### Типы игроков: 
В модели рассматриваются разные типы игроков: агрессивные, осторожные и сбалансированные. Каждый тип игрока использует разные методы для выбора стратегии, что влияет на их поведение в конфликте.

#### Эпсилон-жадная стратегия: 
Для учета исследования новых стратегий игроки время от времени выбирают случайные действия. Этот подход позволяет сбалансировать исследование и эксплуатацию стратегий.

Этот проект демонстрирует, как можно использовать теорию игр для моделирования конфликтов в военных ситуациях с использованием Python.
